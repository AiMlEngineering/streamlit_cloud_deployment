# -*- coding: utf-8 -*-
"""house_preprocessors.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_A8zOnQ9sY-x3aFuxHF75bV0kUFdcyl9
"""

# for typing
import typing as t

# to handle datasets
import numpy as np
import pandas as pd
# for fit_transform object compatible to scikit-learn
# you need to write fit and transform method in child object construction
# base or mother object export from scikit-learn
# for getting and setting variables compatible to scikit-learn variables
from sklearn.base import BaseEstimator, TransformerMixin

# for reproducibility, split size
seed = 0
split_size = 0.3


# """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
# """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
# # DATA PREPARATION AND CLEANING ASSOCIATED TO THE PROBLEM
# """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
# """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
# Retaining the first of cabin value if more than one
class RetainingFirstOfCabinTransform(BaseEstimator, TransformerMixin):
    def is_not_used(self):
        pass

    def __init__(self, variable_list):
        # Check the input of function
        if not isinstance(variable_list, list):
            raise ValueError("variable_list should be a list")

        self.variable_list = variable_list

    # def get_first_cabin(self, row: str) -> float | str:
    def get_first_cabin(self, row: str) -> t.Union[float, str]:
        # Check the input of function
        if not isinstance(row, str):
            raise ValueError("row should be a string")

        self.is_not_used()
        try:
            if isinstance(row, str):
                return row.split()[0]
            else:
                return np.nan
        except IndexError:
            return np.nan

    def fit(self, X, y=None):
        # we need this step to fit the sklearn pipeline
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # return result as self
        return self

    def transform(self, X):
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # so that we do not over-write the original dataframe
        X = X.copy()

        # Generate the data frame to return
        for feature in self.variable_list:
            X[feature] = X[feature].apply(self.get_first_cabin)

        # return result as data frame
        return X


# Extraction of the letter and keep it only in the variable Cabin
class VariableCabinTransform(BaseEstimator, TransformerMixin):
    # Temporal elapsed time transformer

    def __init__(self, variable_list):
        # Check the input of function
        if not isinstance(variable_list, list):
            raise ValueError("variable_list should be a list")

        self.variable_list = variable_list

    def fit(self, X, y=None):
        # we need this step to fit the sklearn pipeline
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # return result as self
        return self

    def transform(self, X):
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # so that we do not over-write the original dataframe
        X = X.copy()

        # Generate the data frame to return
        for feature in self.variable_list:
            X[feature] = X[feature].astype(str).str[0]

        # return result as data frame
        return X


# Extraction title from the name of the variable
class ExtractionTitleFromTheNameTransform(BaseEstimator, TransformerMixin):
    def __init__(self, variable_list):
        # Check the input of function
        if not isinstance(variable_list, list):
            raise ValueError("variable_list should be a list")

        self.variable_list = variable_list

    def get_title(self, passenger: str) -> str:
        import re

        # Check the input of function
        if not isinstance(passenger, str):
            raise ValueError("passenger should be a string")

        # Extract title from name
        line = passenger
        for var in self.variable_list:
            if re.search(var, line):
                var0 = var

        # return result as variable
        return var0

    def fit(self, X, y=None):
        # we need this step to fit the sklearn pipeline
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # return result as self
        return self

    def transform(self, X):
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # so that we do not over-write the original dataframe
        X = X.copy()

        # Generate the data frame to return
        X["title"] = X["name"].apply(self.get_title)

        # return result as data frame
        return X


# Extract important information from variable "title"
class ExtractionAllTitleFromTheNameTransform(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        # we need this step to fit the sklearn pipeline
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # return result as self
        return self

    def get_title(self, input_data: pd.DataFrame) -> pd.DataFrame:
        # Check the input of function
        if not isinstance(input_data, pd.DataFrame):
            raise ValueError("input_data should be a dataframe")

        # so that we do not over-write the original dataframe
        data = input_data.copy()

        # Split the column "name" by "," and " "
        df = data["name"].astype(str).str.split(",", expand=True)
        df = df[1].str.split(" ", expand=True)

        # extract title of name and convert unique value into list
        name_title_uniq_value = df[1].unique().tolist()

        # replace some character in list
        name_title_uniq_value = list(
            map(
                lambda x: x.replace("the", "the Countess.")
                if isinstance(x, str)
                else x,
                name_title_uniq_value,
            )
        )
        name_title_uniq_value = list(
            map(
                lambda x: x.replace(".", "") if isinstance(x, str) else x,
                name_title_uniq_value,
            )
        )

        # Replace the string "the" by "the Countess." and remove "."
        missing_values_mask = df[1] == "the"
        df[1] = np.where(missing_values_mask, "the Countess.", df[1])
        df[1] = df[1].str.replace(".", "")

        # Rename the column "1" by "title", concate with the originale data and
        # drop coolumn "name"
        df.rename(columns={1: "title"}, inplace=True)

        # Associate the original "Nan" value in the dataset generated
        missing_values_mask_origin = data["name"].isnull() | data["name"].isna()
        for var in df.columns.values.tolist():
            df[var] = np.where(missing_values_mask_origin, np.nan, df[var])

        # concatenate data
        df_wn = data.copy().drop(["name"], axis=1)
        final_data_output = pd.concat([df_wn, df[["title"]]], axis=1)

        # return result as data frame
        return final_data_output

    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # so that we do not over-write the original dataframe
        X = X.copy()

        # Apply transform function
        # X = X.apply(self.get_title)
        X = self.get_title(input_data=X)

        # return result as data frame
        return X


# Extract important information from variable "ticket"
class ExtractionSubstringFromTicketTransform(BaseEstimator, TransformerMixin):
    def get_ticket_substring_fit(self, input_data: pd.DataFrame) -> tuple:
        # Check the input of function
        if not isinstance(input_data, pd.DataFrame):
            raise ValueError("input_data should be a dataframe")

        # so that we do not over-write the original dataframe
        data = input_data.copy()

        # Split data with " "
        ticket_new = data["ticket"].copy().astype(str).str.split(" ", expand=True)

        # create new variable and append it into new list
        ticket_new_columns = []
        for ind in ticket_new.columns.values.tolist():
            new_var_name = f"ticket_substr{ind}"
            ticket_new_columns.append(new_var_name)

        # rename the column of data set
        ticket_new.columns = ticket_new_columns

        if "ticket_substr2" in ticket_new_columns:
            # FILL THE NAN VALUE IN THE NEW COLUMN GENERATED
            # list of new variable generated
            new_var_list = ["ticket_substr0", "ticket_substr1"]
            new_var_tofill_list = ["ticket_substr2"]

            # fill the third column values and second columns values contains "None"
            # with numerical value of first column
            for i in range(len(new_var_tofill_list)):
                # get variable
                var = new_var_tofill_list[i]
                var_m1 = new_var_list[i + 1]
                var_m2 = new_var_list[i]

                # Check for NaN values and numerical strings
                missing_values_mask = (
                    ticket_new[var].isna()
                    & ticket_new[var_m1].isna()
                    & ticket_new[var_m2].str.isnumeric()
                )

                # Fill the values checked
                ticket_new[var] = np.where(
                    missing_values_mask, ticket_new[var_m2], ticket_new[var]
                )

            # fill the third column values contains "None" with numerical value of second column
            for i in range(len(new_var_tofill_list)):
                # get variable
                var = new_var_tofill_list[i]
                var_m1 = new_var_list[i + 1]

                # Check for NaN values and numerical strings
                missing_values_mask = (
                    ticket_new[var].isna() & ticket_new[var_m1].str.isnumeric()
                )

                # Fill the values checked
                ticket_new[var] = np.where(
                    missing_values_mask, ticket_new[var_m1], ticket_new[var]
                )

            # FILL THE NAN VALUE IN THE NEW COLUMN GENERATED
            # list of new variable generated
            new_var_list = ["ticket_substr2"]
            new_var_tofill_list = ["ticket_substr1"]

            # fill the second column values with "None" were second and
            # third column have the same value
            for i in range(len(new_var_tofill_list)):
                # get variable
                var = new_var_tofill_list[i]
                var_m = new_var_list[i]

                # Check for equal value between 2 columns
                missing_values_mask = ticket_new[var] == ticket_new[var_m]

                # Fill the values checked
                ticket_new[var] = np.where(missing_values_mask, "None", ticket_new[var])

            # FILL THE NAN VALUE IN THE NEW COLUMN GENERATED
            # list of new variable generated
            new_var_list = ["ticket_substr2"]
            new_var_tofill_list = ["ticket_substr0"]

            # fill the first column values with "None" were first and
            # third column have the same value
            for i in range(len(new_var_tofill_list)):
                # get variable
                var = new_var_tofill_list[i]
                var_m = new_var_list[i]

                # Check for equal value between 2 columns
                missing_values_mask = ticket_new[var] == ticket_new[var_m]

                # Fill the values checked
                ticket_new[var] = np.where(missing_values_mask, "None", ticket_new[var])

        # REPLACE SOME CARACHTERS IN STRINGS
        if "ticket_substr0" in ticket_new_columns:
            ticket_new["ticket_substr0"] = ticket_new["ticket_substr0"].str.replace(
                "/", ""
            )
            ticket_new["ticket_substr0"] = ticket_new["ticket_substr0"].str.replace(
                ".", ""
            )

        if "ticket_substr1" in ticket_new_columns:
            ticket_new["ticket_substr1"] = ticket_new["ticket_substr1"].str.replace(
                ".", ""
            )

        if "ticket_substr2" in ticket_new_columns:
            # REPLACE ALL "None" VALUE BY "NotExist"
            ticket_new["ticket_substr2"] = ticket_new["ticket_substr2"].str.replace(
                "None", "NotExist"
            )
            missing_values_mask = ticket_new["ticket_substr2"].isna()
            ticket_new["ticket_substr2"] = np.where(
                missing_values_mask, "NotExist", ticket_new["ticket_substr2"]
            )

        if "ticket_substr1" in ticket_new_columns:
            ticket_new["ticket_substr1"] = ticket_new["ticket_substr1"].str.replace(
                "None", "NotExist"
            )
            missing_values_mask = ticket_new["ticket_substr1"].isna()
            ticket_new["ticket_substr1"] = np.where(
                missing_values_mask, "NotExist", ticket_new["ticket_substr1"]
            )

        if "ticket_substr0" in ticket_new_columns:
            ticket_new["ticket_substr0"] = ticket_new["ticket_substr0"].str.replace(
                "None", "NotExist"
            )
            missing_values_mask = ticket_new["ticket_substr0"].isna()
            ticket_new["ticket_substr0"] = np.where(
                missing_values_mask, "NotExist", ticket_new["ticket_substr0"]
            )

            missing_values_mask = ticket_new["ticket_substr0"] == "SCParis"
            ticket_new["ticket_substr0"] = np.where(
                missing_values_mask, "SCPARIS", ticket_new["ticket_substr0"]
            )

        # REPLACE ALL "NotExist" VALUE BY "NaN"
        ticket_new = ticket_new.replace("NotExist", np.nan)

        all_features = ["ticket_substr0", "ticket_substr1", "ticket_substr2"]
        unique_dict: dict = {}
        for feat in all_features:
            unique_values = ticket_new[feat].unique().tolist()
            for var in unique_values:
                if var != np.nan:
                    unique_dict[feat] = var
            if feat not in ticket_new.columns.values.tolist():
                ticket_new[feat] = unique_dict[feat]

        # "NaN" VALUE IMPUTATION
        # from feature-engine
        from feature_engine.imputation import (CategoricalImputer,
                                               RandomSampleImputer)

        # Initialize
        ticket_new_t2 = ticket_new

        # imput NaN value in ticket_2 variable
        first_t2_imputer = RandomSampleImputer(
            variables=["ticket_substr2"], random_state=29
        )
        first_t2_imputer.fit(ticket_new_t2.copy())
        ticket_new_t2_ = first_t2_imputer.transform(ticket_new_t2.copy())

        # imput NaN value in ticket_1 variable
        first_t1_imputer = CategoricalImputer(
            variables=["ticket_substr1"], imputation_method="missing"
        )
        first_t1_imputer.fit(ticket_new_t2_)
        ticket_new_t1_ = first_t1_imputer.transform(ticket_new_t2_)

        # imput NaN value in ticket_0 variable
        first_t0_imputer = CategoricalImputer(
            variables=["ticket_substr0"], imputation_method="missing"
        )
        first_t0_imputer.fit(ticket_new_t1_)

        # return result as tuple
        return (first_t0_imputer, first_t1_imputer, first_t2_imputer, unique_dict)

    def fit(self, X, y=None):
        # we need this step to fit the sklearn pipeline
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # get imputers trained for transform step
        (
            self.first_t0_imputer,
            self.first_t1_imputer,
            self.first_t2_imputer,
            self.unique_dict,
        ) = self.get_ticket_substring_fit(input_data=X)

        # return result as self
        return self

    def get_ticket_substring_transform(self, input_data: pd.DataFrame) -> pd.DataFrame:
        # Check the input of function
        if not isinstance(input_data, pd.DataFrame):
            raise ValueError("input_data should be a dataframe")

        # so that we do not over-write the original dataframe
        data = input_data.copy()

        # Split data with " "
        ticket_new = data["ticket"].copy().astype(str).str.split(" ", expand=True)

        # create new variable and append it into new list
        ticket_new_columns = []
        for ind in ticket_new.columns.values.tolist():
            new_var_name = f"ticket_substr{ind}"
            ticket_new_columns.append(new_var_name)

        # rename the column of data set
        ticket_new.columns = ticket_new_columns

        if "ticket_substr2" in ticket_new_columns:
            # FILL THE NAN VALUE IN THE NEW COLUMN GENERATED
            # list of new variable generated
            new_var_list = ["ticket_substr0", "ticket_substr1"]
            new_var_tofill_list = ["ticket_substr2"]

            # fill the third column values and second columns values contains "None"
            # with numerical value of first column
            for i in range(len(new_var_tofill_list)):
                # get variable
                var = new_var_tofill_list[i]
                var_m1 = new_var_list[i + 1]
                var_m2 = new_var_list[i]

                # Check for NaN values and numerical strings
                missing_values_mask = (
                    ticket_new[var].isna()
                    & ticket_new[var_m1].isna()
                    & ticket_new[var_m2].str.isnumeric()
                )

                # Fill the values checked
                ticket_new[var] = np.where(
                    missing_values_mask, ticket_new[var_m2], ticket_new[var]
                )

            # fill the third column values contains "None" with numerical value of second column
            for i in range(len(new_var_tofill_list)):
                # get variable
                var = new_var_tofill_list[i]
                var_m1 = new_var_list[i + 1]

                # Check for NaN values and numerical strings
                missing_values_mask = (
                    ticket_new[var].isna() & ticket_new[var_m1].str.isnumeric()
                )

                # Fill the values checked
                ticket_new[var] = np.where(
                    missing_values_mask, ticket_new[var_m1], ticket_new[var]
                )

            # FILL THE NAN VALUE IN THE NEW COLUMN GENERATED
            # list of new variable generated
            new_var_list = ["ticket_substr2"]
            new_var_tofill_list = ["ticket_substr1"]

            # fill the second column values with "None" were second and
            # third column have the same value
            for i in range(len(new_var_tofill_list)):
                # get variable
                var = new_var_tofill_list[i]
                var_m = new_var_list[i]

                # Check for equal value between 2 columns
                missing_values_mask = ticket_new[var] == ticket_new[var_m]

                # Fill the values checked
                ticket_new[var] = np.where(missing_values_mask, "None", ticket_new[var])

            # FILL THE NAN VALUE IN THE NEW COLUMN GENERATED
            # list of new variable generated
            new_var_list = ["ticket_substr2"]
            new_var_tofill_list = ["ticket_substr0"]

            # fill the first column values with "None" were first and
            # third column have the same value
            for i in range(len(new_var_tofill_list)):
                # get variable
                var = new_var_tofill_list[i]
                var_m = new_var_list[i]

                # Check for equal value between 2 columns
                missing_values_mask = ticket_new[var] == ticket_new[var_m]

                # Fill the values checked
                ticket_new[var] = np.where(missing_values_mask, "None", ticket_new[var])

        # REPLACE SOME CARACHTERS IN STRINGS
        if "ticket_substr0" in ticket_new_columns:
            ticket_new["ticket_substr0"] = ticket_new["ticket_substr0"].str.replace(
                "/", ""
            )
            ticket_new["ticket_substr0"] = ticket_new["ticket_substr0"].str.replace(
                ".", ""
            )

        if "ticket_substr1" in ticket_new_columns:
            ticket_new["ticket_substr1"] = ticket_new["ticket_substr1"].str.replace(
                ".", ""
            )

        if "ticket_substr2" in ticket_new_columns:
            # REPLACE ALL "None" VALUE BY "NotExist"
            ticket_new["ticket_substr2"] = ticket_new["ticket_substr2"].str.replace(
                "None", "NotExist"
            )
            missing_values_mask = ticket_new["ticket_substr2"].isna()
            ticket_new["ticket_substr2"] = np.where(
                missing_values_mask, "NotExist", ticket_new["ticket_substr2"]
            )

        if "ticket_substr1" in ticket_new_columns:
            ticket_new["ticket_substr1"] = ticket_new["ticket_substr1"].str.replace(
                "None", "NotExist"
            )
            missing_values_mask = ticket_new["ticket_substr1"].isna()
            ticket_new["ticket_substr1"] = np.where(
                missing_values_mask, "NotExist", ticket_new["ticket_substr1"]
            )

        if "ticket_substr0" in ticket_new_columns:
            ticket_new["ticket_substr0"] = ticket_new["ticket_substr0"].str.replace(
                "None", "NotExist"
            )
            missing_values_mask = ticket_new["ticket_substr0"].isna()
            ticket_new["ticket_substr0"] = np.where(
                missing_values_mask, "NotExist", ticket_new["ticket_substr0"]
            )

            missing_values_mask = ticket_new["ticket_substr0"] == "SCParis"
            ticket_new["ticket_substr0"] = np.where(
                missing_values_mask, "SCPARIS", ticket_new["ticket_substr0"]
            )

        # REPLACE ALL "NotExist" VALUE BY "NaN"
        ticket_new = ticket_new.replace("NotExist", np.nan)

        all_features = ["ticket_substr0", "ticket_substr1", "ticket_substr2"]
        for feat in all_features:
            if feat not in ticket_new.columns.values.tolist():
                ticket_new[feat] = self.unique_dict[feat]

        # Initialize
        ticket_new_t2 = ticket_new

        # imput NaN value in ticket_2 variable
        ticket_new_t2 = self.first_t2_imputer.transform(ticket_new_t2)

        # imput NaN value in ticket_1 variable
        ticket_new_t1 = self.first_t1_imputer.transform(ticket_new_t2)

        # imput NaN value in ticket_0 variable
        ticket_new_t0 = self.first_t0_imputer.transform(ticket_new_t1)

        if "ticket_substr2" in ticket_new_columns:
            # CAST SOME CATEGORICAL VARIABLE GENERATED AS NUMERICAL VARIABLE AS INTEGER
            # numerical variable needed to be casted
            numvar_casted = ["ticket_substr2"]

            # cast numerical variables as floats
            for var in numvar_casted:
                ticket_new_t0[var] = ticket_new_t0[var].astype("float64")

        # Associate the original "Nan" value in the dataset generated
        missing_values_mask_origin = data["ticket"].isnull() | data["ticket"].isna()
        for var in ticket_new_t0.columns.values.tolist():
            ticket_new_t0[var] = np.where(
                missing_values_mask_origin, np.nan, ticket_new_t0[var]
            )

        # concatenate data
        df_wt = data.copy().drop(["ticket"], axis=1)
        final_data_output = pd.concat([df_wt, ticket_new_t0], axis=1)

        # return result as data frame
        return final_data_output

    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # so that we do not over-write the original dataframe
        X = X.copy()

        # Apply transform function
        # X = X.apply(self.get_ticket_substring)
        X = self.get_ticket_substring_transform(input_data=X)

        # return resulst as data frame
        return X


# Extract important information from variable "cabin"
class ExtractionSubstringFromCabinTransform(BaseEstimator, TransformerMixin):
    def get_cabin_substring_fit(self, input_data: pd.DataFrame) -> tuple:
        # Check the input of function
        if not isinstance(input_data, pd.DataFrame):
            raise ValueError("input_data should be a dataframe")

        # so that we do not over-write the original dataframe
        data = input_data.copy()

        # copy original dataset
        dff = data[["cabin"]].copy()

        # split data into home and destination
        dff_tr = dff["cabin"].astype(str).str.split(" ", expand=True)

        # create an Empty DataFrame object
        final_data = pd.DataFrame()

        # Replace and split data by some character
        if 0 in dff_tr.columns.values.tolist():
            dff_tr["zeros"] = dff_tr[0].str.replace(" ", "")
            dff_tr_0 = dff_tr["zeros"].str.split("", expand=True)
            for count in range(10):
                if count not in dff_tr_0.columns.tolist():
                    dff_tr_0[count] = np.nan
            # Create dataframe
            final_data["cabin_substr1"] = dff_tr_0[1]
            final_data["cabin_substr2"] = dff_tr_0[2]
            final_data["cabin_substr3"] = dff_tr_0[3]
            final_data["cabin_substr4"] = dff_tr_0[4]

        if 1 in dff_tr.columns.values.tolist():
            dff_tr["one"] = dff_tr[1].str.replace(" ", "")
            dff_tr_1 = dff_tr["one"].str.split("", expand=True)
            for count in range(10):
                if count not in dff_tr_1.columns.tolist():
                    dff_tr_1[count] = np.nan
            # Create dataframe
            final_data["cabin_substr5"] = dff_tr_1[1]
            final_data["cabin_substr6"] = dff_tr_1[2]
            final_data["cabin_substr7"] = dff_tr_1[3]

        if 2 in dff_tr.columns.values.tolist():
            dff_tr["two"] = dff_tr[2].str.replace(" ", "")
            dff_tr_2 = dff_tr["two"].str.split("", expand=True)
            for count in range(10):
                if count not in dff_tr_2.columns.tolist():
                    dff_tr_2[count] = np.nan
            # Create dataframe
            final_data["cabin_substr8"] = dff_tr_2[1]
            final_data["cabin_substr9"] = dff_tr_2[2]
            final_data["cabin_substr10"] = dff_tr_2[3]

        if 3 in dff_tr.columns.values.tolist():
            dff_tr["tree"] = dff_tr[3].str.replace(" ", "")
            dff_tr_3 = dff_tr["tree"].str.split("", expand=True)
            for count in range(10):
                if count not in dff_tr_3.columns.tolist():
                    dff_tr_3[count] = np.nan
            # Create dataframe
            final_data["cabin_substr11"] = dff_tr_3[1]
            final_data["cabin_substr12"] = dff_tr_3[2]
            final_data["cabin_substr13"] = dff_tr_3[3]

        all_features = [
            "cabin_substr1",
            "cabin_substr2",
            "cabin_substr3",
            "cabin_substr4",
            "cabin_substr5",
            "cabin_substr6",
            "cabin_substr7",
            "cabin_substr8",
            "cabin_substr9",
            "cabin_substr10",
            "cabin_substr11",
            "cabin_substr12",
            "cabin_substr13",
        ]
        unique_dict: dict = {}
        for feat in all_features:
            unique_values = final_data[feat].unique().tolist()
            for var in unique_values:
                if var != np.nan:
                    unique_dict[feat] = var
            if feat not in final_data.columns.values.tolist():
                final_data[feat] = unique_dict[feat]

        # Replace missing, None and empty cells by Nan
        missing_values_mask_origin = data["cabin"].isnull() | data["cabin"].isna()
        for var in final_data.columns.values.tolist():
            final_data[var] = np.where(
                missing_values_mask_origin, np.nan, final_data[var]
            )
            missing_values_mask_gener = (
                final_data[var].isnull() | final_data[var].isna()
            )
            final_data[var] = np.where(
                missing_values_mask_gener, np.nan, final_data[var]
            )
            missing_values_mask_gener = final_data[var] == ""
            final_data[var] = np.where(
                missing_values_mask_gener, np.nan, final_data[var]
            )

        # "NaN" VALUE IMPUTATION
        # from feature-engine
        from feature_engine.imputation import \
            RandomSampleImputer  # , CategoricalImputer

        # imput NaN value generated when manipulate dataset
        # imputer = CategoricalImputer(
        #     variables=final_data.columns.values.tolist(),
        #     imputation_method="missing"
        # )
        imputer = RandomSampleImputer(
            variables=final_data.columns.values.tolist(), random_state=seed
        )
        imputer.fit(final_data)

        # return result as tuple
        return imputer, unique_dict

    def fit(self, X, y=None):
        # we need this step to fit the sklearn pipeline
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # get imputers trained for transform step
        self.imputer, self.unique_dict = self.get_cabin_substring_fit(input_data=X)

        # return result as self
        return self

    def get_cabin_substring_transform(self, input_data: pd.DataFrame) -> pd.DataFrame:
        # Check the input of function
        if not isinstance(input_data, pd.DataFrame):
            raise ValueError("input_data should be a dataframe")

        # so that we do not over-write the original dataframe
        data = input_data.copy()

        # copy original dataset
        dff = data[["cabin"]].copy()

        # split data into home and destination
        dff_tr = dff["cabin"].astype(str).str.split(" ", expand=True)

        # create an Empty DataFrame object
        final_data = pd.DataFrame()

        # Replace and split data by some character
        if 0 in dff_tr.columns.values.tolist():
            dff_tr["zeros"] = dff_tr[0].str.replace(" ", "")
            dff_tr_0 = dff_tr["zeros"].str.split("", expand=True)
            for count in range(10):
                if count not in dff_tr_0.columns.tolist():
                    dff_tr_0[count] = np.nan
            # Create dataframe
            final_data["cabin_substr1"] = dff_tr_0[1]
            final_data["cabin_substr2"] = dff_tr_0[2]
            final_data["cabin_substr3"] = dff_tr_0[3]
            final_data["cabin_substr4"] = dff_tr_0[4]

        if 1 in dff_tr.columns.values.tolist():
            dff_tr["one"] = dff_tr[1].str.replace(" ", "")
            dff_tr_1 = dff_tr["one"].str.split("", expand=True)
            for count in range(10):
                if count not in dff_tr_1.columns.tolist():
                    dff_tr_1[count] = np.nan
            # Create dataframe
            final_data["cabin_substr5"] = dff_tr_1[1]
            final_data["cabin_substr6"] = dff_tr_1[2]
            final_data["cabin_substr7"] = dff_tr_1[3]

        if 2 in dff_tr.columns.values.tolist():
            dff_tr["two"] = dff_tr[2].str.replace(" ", "")
            dff_tr_2 = dff_tr["two"].str.split("", expand=True)
            for count in range(10):
                if count not in dff_tr_2.columns.tolist():
                    dff_tr_2[count] = np.nan
            # Create dataframe
            final_data["cabin_substr8"] = dff_tr_2[1]
            final_data["cabin_substr9"] = dff_tr_2[2]
            final_data["cabin_substr10"] = dff_tr_2[3]

        if 3 in dff_tr.columns.values.tolist():
            dff_tr["tree"] = dff_tr[3].str.replace(" ", "")
            dff_tr_3 = dff_tr["tree"].str.split("", expand=True)
            for count in range(10):
                if count not in dff_tr_3.columns.tolist():
                    dff_tr_3[count] = np.nan
            # Create dataframe
            final_data["cabin_substr11"] = dff_tr_3[1]
            final_data["cabin_substr12"] = dff_tr_3[2]
            final_data["cabin_substr13"] = dff_tr_3[3]

        all_features = [
            "cabin_substr1",
            "cabin_substr2",
            "cabin_substr3",
            "cabin_substr4",
            "cabin_substr5",
            "cabin_substr6",
            "cabin_substr7",
            "cabin_substr8",
            "cabin_substr9",
            "cabin_substr10",
            "cabin_substr11",
            "cabin_substr12",
            "cabin_substr13",
        ]
        for feat in all_features:
            if feat not in final_data.columns.values.tolist():
                final_data[feat] = self.unique_dict[feat]

        # Replace missing, None and empty cells by Nan
        missing_values_mask_origin = data["cabin"].isnull() | data["cabin"].isna()
        for var in final_data.columns.values.tolist():  # initial_features:  #
            final_data[var] = np.where(
                missing_values_mask_origin, np.nan, final_data[var]
            )
            missing_values_mask_gener = (
                final_data[var].isnull() | final_data[var].isna()
            )
            final_data[var] = np.where(
                missing_values_mask_gener, np.nan, final_data[var]
            )
            missing_values_mask_gener = final_data[var] == ""
            final_data[var] = np.where(
                missing_values_mask_gener, np.nan, final_data[var]
            )

        # imput NaN value generated when manipulate dataset
        final_data_wnan = self.imputer.transform(final_data)

        # Imput the original "Nan" value in the dataset generated
        imp_val_origin_nan = 20000000000
        missing_values_mask_origin = data["cabin"].isnull() | data["cabin"].isna()
        for var in final_data_wnan.columns.values.tolist():  # initial_features:  #
            final_data_wnan[var] = np.where(
                missing_values_mask_origin,
                str(imp_val_origin_nan),
                final_data_wnan[var],
            )

        # cast numerical variables as floats
        numvar_casted = ["cabin_substr2", "cabin_substr3", "cabin_substr4"]
        check = all(
            item in final_data_wnan.columns.values.tolist() for item in numvar_casted
        )
        if check is True:
            for var in numvar_casted:
                final_data_wnan[var] = final_data_wnan[var].astype("float64")

        # cast numerical variables as floats
        numvar_casted = ["cabin_substr6", "cabin_substr7"]
        check = all(
            item in final_data_wnan.columns.values.tolist() for item in numvar_casted
        )
        if check is True:
            for var in numvar_casted:
                final_data_wnan[var] = final_data_wnan[var].astype("float64")

        # cast numerical variables as floats
        numvar_casted = ["cabin_substr9", "cabin_substr10"]
        check = all(
            item in final_data_wnan.columns.values.tolist() for item in numvar_casted
        )
        if check is True:
            for var in numvar_casted:
                final_data_wnan[var] = final_data_wnan[var].astype("float64")

        # cast numerical variables as floats
        numvar_casted = ["cabin_substr12", "cabin_substr13"]
        check = all(
            item in final_data_wnan.columns.values.tolist() for item in numvar_casted
        )
        if check is True:
            for var in numvar_casted:
                final_data_wnan[var] = final_data_wnan[var].astype("float64")

        # Associate the original "Nan" value in the dataset generated
        missing_values_mask_origin = data["cabin"].isnull() | data["cabin"].isna()
        for var in final_data_wnan.columns.values.tolist():  # initial_features:  #
            final_data_wnan[var] = np.where(
                missing_values_mask_origin, np.nan, final_data_wnan[var]
            )

        # create the drop transformers with feature engine
        final_data_wnan_drop = (
            final_data_wnan  # self.drop_dup_feat.transform(final_data_wnan)
        )

        # concatenate data
        df_wc = data.copy().drop(["cabin"], axis=1)
        if "cabin_substr12" in final_data_wnan_drop.columns.values.tolist():
            final_data_output = pd.concat(
                [df_wc, final_data_wnan_drop.drop(["cabin_substr12"], axis=1)], axis=1
            )
        else:
            final_data_output = pd.concat([df_wc, final_data_wnan_drop], axis=1)

        # return result as data frame
        return final_data_output

    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # so that we do not over-write the original dataframe
        X = X.copy()

        # Apply transform function
        # X = X.apply(self.get_cabin_substring)
        X = self.get_cabin_substring_transform(input_data=X)

        # return result as data frame
        return X


# Extract important information from variable "home.dest"
class ExtractionSubstringFromHomeDestTransform(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        # we need this step to fit the sklearn pipeline
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # return result as self
        return self

    # Function to get country from city name
    def get_country(self, city: str):
        # Check the input of function
        if not isinstance(city, str):
            raise ValueError("city should be a string")

        # Initialize mask
        mask = city

        # Load world cities dataset
        world_cities_df = pd.read_csv("./raw_inputs/worldcities.csv")

        for i in range(0, world_cities_df.shape[0]):
            # if(op.contains(world_cities_df.loc[i, 'city_ascii'], city)):
            if world_cities_df.loc[i, "city_ascii"] in city:
                mask = world_cities_df.loc[i, "city_ascii"]
            else:
                pass

        city_row = world_cities_df[world_cities_df["city_ascii"] == mask]
        if not city_row.empty:
            return city_row["country"].iloc[0]
        else:
            return None

    # Function to remove the last two uppercase substrings
    def remove_last_two_uppercase(self, s):
        parts = s.split(", ")
        if len(parts) > 1:
            # Process only if there are at least two parts separated by comma
            last_part = parts[-1]
            last_part = last_part[:-3] if last_part[-3:].isupper() else last_part
            parts[-1] = last_part

        # return result
        return ", ".join(parts)

    def get_homedest_substring(self, input_data: pd.DataFrame) -> pd.DataFrame:
        # Check the input of function
        if not isinstance(input_data, pd.DataFrame):
            raise ValueError("input_data should be a dataframe")

        # Mapping list
        United_States = [
            "Fond du Lac ",
            "St Louis ",
            "Pomeroy ",
            "Tuxedo Park ",
            "Elkins Park ",
            "Cambridge ",
            "Green Bay ",
            "Bronx ",
            "Holley ",
            "Indianapolis ",
            "Harrisburg ",
            "Bennington ",
            "St James Long Island ",
            "Deer Lodge ",
            "Kingston Surrey",
            "Southington ",
            "Austria Hungary ",
            "Austria Hungary",
            "Dowagiac ",
            "Tampico ",
            "Gallipolis Ohio ",
            "Bryn Mawr ",
            "Dorchester ",
            "Bryn Mawr PA ",
            "Plymouth Dorset ",
            "Youngstown ",
            "Los Angeles ",
            "West Hoboken ",
            "Boston ",
            "Waukegan Chicago ",
            "Lake Arthur Chavez County ",
            "Cooperstown",
            "Cooperstown ",
            "Amenia ",
            "Roachdale ",
            "Deephaven ",
            "Cincinatti ",
            "Haddenfield ",
            "Woodford County ",
            "Denmark ",
            "Perkins County ",
            "Effington Rut ",
            "Illinois ",
            " Bronx ",
            " Houghton ",
            " Bangor ",
            " Benton Harbour ",
            " Bennington ",
            " Massachusetts",
            " Staten Island ",
            " Calumet ",
            " Belfast",
            " Birmingham",
            " Cooperstown ",
        ]

        Spain = ["Madrid Spain", "Barcelona Spain ", "Spain "]
        Canada = [
            "Hamilton ",
            "Toronto ",
            "Calgary ",
            "Sault St Marie ",
            " Hayling Island Hants",
            " Chesterville ",
        ]
        Portugal = ["Portugal ", "Portugal"]
        Belgium = ["Belgium  Montreal ", "Belgium Detroit ", "Antwerp Belgium "]
        Australia = ["Sydney Australia", "Australia Fingal "]
        Switzerland = [
            "Basel Switzerland",
            "Zurich Switzerland",
            "Geneva Switzerland ",
            "Berne Switzerland ",
            "Altdorf Switzerland",
        ]
        Thailand = ["Bangkok Thailand "]
        Russia = ["Russia New York ", "Russia", "Moscow "]
        Japan = ["Tokyo Japan"]
        South_Africa = ["Cape Town South Africa "]

        Sweden = [
            "Stockholm Sweden ",
            "Stockholm Sweden",
            "Skara Sweden ",
            "Goteborg Sweden ",
            "Sweden ",
            "Asarum Sweden Brooklyn ",
            "Sweden Akeley ",
            "Sweden Winnipeg ",
            "Vadsbro Sweden Ministee ",
            "Sweden Chicago ",
            "Sweden Joliet ",
            "Sweden  Worcester ",
            "Oskarshamn Sweden Minneapolis ",
            "Krakoryd Sweden Bloomington ",
            "Krakudden Sweden Moune ",
            "Stockholm Sweden New York",
            "Medeltorp Sweden Chicago ",
            "Dagsas Sweden Fower ",
            "Goteborg Sweden Huntley ",
            "Norrlot Sweden Chicago ",
            "Tofta Sweden Joliet ",
            "Karberg Sweden Jerome Junction ",
            "Myren Sweden New York ",
        ]
        Peru = ["Lima Peru"]

        Ireland = [
            "Co Clare Ireland Washington ",
            "Co Limerick Ireland Sherbrooke ",
            "Co Cork Ireland Charlestown ",
            "Kingwilliamstown Co Cork Ireland Glens Falls ",
            "Kingwilliamstown Co Cork Ireland New York ",
            "Ireland Chicago ",
            "Co Cork Ireland Roxbury ",
            "Co Sligo Ireland New York ",
            "Ireland Philadelphia ",
            "Co Longford Ireland New York ",
            "Co Sligo Ireland Hartford ",
            "Ireland New York ",
            "Ireland Brooklyn ",
            "Co Athlone Ireland New York ",
            "Kilmacowen Co Sligo Ireland New York ",
            "Ireland New York ",
            "Aughnacliff Co Longford Ireland New York ",
            "Ireland Chicago ",
            "Ireland New York ",
            "Co Longford Ireland New York ",
            "Ireland",
        ]

        United_Kingdom = [
            "Devonport England",
            "New Forest England",
            "St Leonards on Sea England Ohio",
            "Pondersend England ",
            "Cornwall England Houghton ",
            "Penzance Cornwall ",
            "St Ives Cornwall ",
            "Cornwall ",
            "Cornwall",
            "St Austall Cornwall",
            "Windsor England New York ",
            "England Albion ",
            "Treherbert Cardiff Wales",
            "Southsea Hants",
            "Birkdale England Cleveland Ohio",
            "Westcliff on Sea Essex",
            "England Salt Lake City Utah",
            "Warwick England",
            "Lyndhurst England",
            "Walthamstow England",
            "Worcester England",
            "England New York ",
            "England Brooklyn ",
            "Bristol England Cleveland ",
            "Bournemouth England Newark ",
            "West Bromwich England Pontiac ",
            "Devon England Wichita ",
            "Rotherfield Sussex England Essex Co ",
            "Bridgwater Somerset England",
            "Strood Kent England Detroit ",
            "West Hampstead London ",
            "St Anne's on Sea Lancashire",
            "Ascot Berkshire ",
            "Surbiton Hill Surrey",
            "Streatham Surrey",
            "Denmark Hill Surrey ",
            "Bournmouth England",
            "Bournemouth England",
            "Wiltshire England Niagara Falls ",
            "Little Onn Hall Staffs",
            "Isle of Wight England",
            "Isleworth England",
            "Guernsey",
            "England",
            "England ",
            "Guernsey ",
            "Halesworth England",
            "Gunnislake England ",
            "Guernsey England ",
            "Yoevil England ",
            "Bridgerule Devon",
            "England Oglesby ",
        ]

        Finland = [
            "Finland Sudbury ",
            "Taalintehdas Finland Hoboken ",
            "Salo Finland Astoria ",
            "Ruotsinphyhtaa Finland New York ",
            "Ruotsinphytaa Finland New York ",
            "Tranvik Finland New York",
            "Helsinki Finland Ashtabula Ohio",
            "Finland ",
        ]

        Norway = [
            "Brennes Norway New York",
            "Foresvik Norway Portland ",
            "Oslo Norway Cameron ",
            "Norway Los Angeles ",
            "Oslo Norway Bayonne ",
            "Bergen Norway",
        ]

        Hong_Kong = ["Hong Kong New York "]

        Bulgaria = ["Bulgaria Chicago ", "Bulgaria Coon Rapids "]

        Greece = ["Greece"]

        Syria = [
            "Syria Fredericksburg ",
            "Syria New York ",
            "Syria Kent ",
            "Syria Youngstown ",
            "Syria",
        ]

        Netherlands = ["Rotterdam Netherlands"]

        Italy = ["Lucca Italy ", "Lucca Italy ", "Italy Philadelphia "]
        Mexico = ["Mexico City Mexico"]
        Argentina = ["Argentina"]
        Croatia = ["Croatia"]
        Austria = ["Austria"]

        Brazil = [" Sau Paulo Brazil"]

        # so that we do not over-write the original dataframe
        data = input_data.copy()

        # make a copy of column to treat
        data_to_transform = data[["homedest"]].copy()

        # split data into home and destination
        data_tr0 = data_to_transform["homedest"].astype(str).str.split("/", expand=True)

        # rename the colum generated in dataset
        data_tr0.rename(
            columns={0: "home", 1: "destination1", 2: "destination2"}, inplace=True
        )
        if "home" not in data_tr0.columns.values.tolist():
            data_tr0["home"] = np.nan
        if "destination1" not in data_tr0.columns.values.tolist():
            data_tr0["destination1"] = np.nan
        if "destination2" not in data_tr0.columns.values.tolist():
            data_tr0["destination2"] = np.nan

        # Apply the function to the home_tr1
        data_tr0["home_tr1"] = (
            data_tr0["home"].dropna().apply(self.remove_last_two_uppercase)
        )

        # Remove some carachters in the dataset
        data_tr0["home_tr1"] = data_tr0["home_tr1"].str.replace(",", "")
        data_tr0["home_tr1"] = data_tr0["home_tr1"].str.replace("-", " ")

        # Apply the function to the city column
        data_tr0["home"] = data_tr0["home_tr1"].dropna().apply(self.get_country)

        # Map city to right country
        for i in range(0, data_tr0.shape[0]):
            if i in data_tr0.index:  # check if data set index contains i
                if data_tr0.loc[i, "home_tr1"] in United_States:
                    data_tr0.loc[i, "home"] = "United States"
                elif data_tr0.loc[i, "home_tr1"] in Spain:
                    data_tr0.loc[i, "home"] = "Spain"
                elif data_tr0.loc[i, "home_tr1"] in Canada:
                    data_tr0.loc[i, "home"] = "Canada"
                elif data_tr0.loc[i, "home_tr1"] in Portugal:
                    data_tr0.loc[i, "home"] = "Portugal"
                elif data_tr0.loc[i, "home_tr1"] in Belgium:
                    data_tr0.loc[i, "home"] = "Belgium"
                elif data_tr0.loc[i, "home_tr1"] in Australia:
                    data_tr0.loc[i, "home"] = "Australia"
                elif data_tr0.loc[i, "home_tr1"] in Switzerland:
                    data_tr0.loc[i, "home"] = "Switzerland"
                elif data_tr0.loc[i, "home_tr1"] in Thailand:
                    data_tr0.loc[i, "home"] = "Thailand"
                elif data_tr0.loc[i, "home_tr1"] in Russia:
                    data_tr0.loc[i, "home"] = "Russia"
                elif data_tr0.loc[i, "home_tr1"] in Japan:
                    data_tr0.loc[i, "home"] = "Japan"
                elif data_tr0.loc[i, "home_tr1"] in South_Africa:
                    data_tr0.loc[i, "home"] = "South Africa"
                elif data_tr0.loc[i, "home_tr1"] in Sweden:
                    data_tr0.loc[i, "home"] = "Sweden"
                elif data_tr0.loc[i, "home_tr1"] in Peru:
                    data_tr0.loc[i, "home"] = "Peru"
                elif data_tr0.loc[i, "home_tr1"] in Ireland:
                    data_tr0.loc[i, "home"] = "Ireland"
                elif data_tr0.loc[i, "home_tr1"] in United_Kingdom:
                    data_tr0.loc[i, "home"] = "United Kingdom"
                elif data_tr0.loc[i, "home_tr1"] in Finland:
                    data_tr0.loc[i, "home"] = "Finland"
                elif data_tr0.loc[i, "home_tr1"] in Norway:
                    data_tr0.loc[i, "home"] = "Norway"
                elif data_tr0.loc[i, "home_tr1"] in Hong_Kong:
                    data_tr0.loc[i, "home"] = "Hong Kong"
                elif data_tr0.loc[i, "home_tr1"] in Bulgaria:
                    data_tr0.loc[i, "home"] = "Bulgaria"
                elif data_tr0.loc[i, "home_tr1"] in Greece:
                    data_tr0.loc[i, "home"] = "Greece"
                elif data_tr0.loc[i, "home_tr1"] in Syria:
                    data_tr0.loc[i, "home"] = "Syria"
                elif data_tr0.loc[i, "home_tr1"] in Netherlands:
                    data_tr0.loc[i, "home"] = "Netherlands"
                elif data_tr0.loc[i, "home_tr1"] in Italy:
                    data_tr0.loc[i, "home"] = "Italy"
                elif data_tr0.loc[i, "home_tr1"] in Mexico:
                    data_tr0.loc[i, "home"] = "Mexico"
                elif data_tr0.loc[i, "home_tr1"] in Argentina:
                    data_tr0.loc[i, "home"] = "Argentina"
                elif data_tr0.loc[i, "home_tr1"] in Croatia:
                    data_tr0.loc[i, "home"] = "Croatia"
                elif data_tr0.loc[i, "home_tr1"] in Austria:
                    data_tr0.loc[i, "home"] = "Austria"

        # copy the dataset
        data_tr0_dest = data_tr0.copy()

        # Filter the DataFrame based on None values in the specified column
        missing_values_mask = (
            data_tr0_dest["destination1"].isnull()
            & data_tr0_dest["destination2"].isnull()
        )
        data_tr0_dest["destination"] = np.where(
            missing_values_mask, "United States", data_tr0_dest["destination1"]
        )

        # Apply the function to the home_tr1
        data_tr0_dest["destination1_tr1"] = (
            data_tr0_dest["destination1"].dropna().apply(self.remove_last_two_uppercase)
        )
        data_tr0_dest["destination2_tr1"] = (
            data_tr0_dest["destination2"].dropna().apply(self.remove_last_two_uppercase)
        )

        # Remove some carachters in the dataset
        if data_tr0_dest["destination1_tr1"].dtype == object:
            data_tr0_dest["destination1_tr1"] = data_tr0_dest[
                "destination1_tr1"
            ].str.replace(",", "")
            data_tr0_dest["destination1_tr1"] = data_tr0_dest[
                "destination1_tr1"
            ].str.replace("-", " ")
        if data_tr0_dest["destination2_tr1"].dtype == object:
            data_tr0_dest["destination2_tr1"] = data_tr0_dest[
                "destination2_tr1"
            ].str.replace(",", "")
            data_tr0_dest["destination2_tr1"] = data_tr0_dest[
                "destination2_tr1"
            ].str.replace("-", " ")

        # Apply the function to the city column
        data_tr0_dest["destination1_country"] = (
            data_tr0_dest["destination1_tr1"].dropna().apply(self.get_country)
        )
        data_tr0_dest["destination2_country"] = (
            data_tr0_dest["destination2_tr1"].dropna().apply(self.get_country)
        )

        # Map city to right country
        for i in range(0, data_tr0_dest.shape[0]):
            if i in data_tr0_dest.index:  # check if data set index contains i
                if data_tr0_dest.loc[i, "destination1_tr1"] in United_States:
                    data_tr0_dest.loc[i, "destination1_country"] = "United States"
                elif data_tr0_dest.loc[i, "destination1_tr1"] in Brazil:
                    data_tr0_dest.loc[i, "destination1_country"] = "Brazil"
                elif data_tr0_dest.loc[i, "destination1_tr1"] in Canada:
                    data_tr0_dest.loc[i, "destination1_country"] = "Canada"

        # Replace "destination1_country" cells witch are empty by
        # "destination2_country" witch are not.
        if not data_tr0_dest["destination2_country"].empty:
            missing_values_mask = (
                data_tr0_dest["destination1_country"].isnull()
                | data_tr0_dest["destination1_country"].isna()
            )
        data_tr0_dest["destination1_country"] = np.where(
            missing_values_mask,
            data_tr0_dest["destination2_country"],
            data_tr0_dest["destination1_country"],
        )

        # Filter the DataFrame based on None values in the specified column
        missing_values_mask = (
            data_tr0_dest["destination1"].isnull()
            & data_tr0_dest["destination2"].isnull()
        )
        data_tr0_dest["destination1_country"] = np.where(
            missing_values_mask, "United States", data_tr0_dest["destination1_country"]
        )

        # Replace 'France' by 'United States' in the "destination1_country" column
        for i in range(0, data_tr0_dest.shape[0]):
            if i in data_tr0_dest.index:  # check if data set index contains i
                if data_tr0_dest.loc[i, "destination1_country"] in ["France"]:
                    data_tr0_dest.loc[i, "destination1_country"] = "United States"

        # Replace all values of "destination" column by "destination1_country"
        data_tr0_dest["destination"] = data_tr0_dest["destination1_country"]

        # Replace "destination" cells contains NaN by "United States"
        # when 'home' is not empty
        if not data_tr0_dest["home"].empty:
            missing_values_mask = (
                data_tr0_dest["destination"].isnull()
                | data_tr0_dest["destination"].isna()
            )
        data_tr0_dest["destination"] = np.where(
            missing_values_mask, "United States", data_tr0_dest["destination"]
        )

        # Maintain in the new data the Nan value in the original data
        missing_values_mask = (
            data_to_transform["homedest"].isna()
            | data_to_transform["homedest"].isnull()
        )
        data_tr0_dest["destination"] = np.where(
            missing_values_mask,
            data_to_transform["homedest"],
            data_tr0_dest["destination"],
        )

        # concatenate data
        df_whd = data.copy().drop(["homedest"], axis=1)
        final_data_output = pd.concat(
            [df_whd, data_tr0_dest[["home", "destination"]]], axis=1
        )

        # return result as data frame
        return final_data_output

    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # so that we do not over-write the original dataframe
        X = X.copy()

        # Apply transform function
        # X = X.apply(self.get_homedest_substring)
        X = self.get_homedest_substring(input_data=X)

        # return result as data frame
        return X


# Check and Rename the name of column "home.dest" into "homedest"
class CheckAndRenameHomedestColumnNameTransform(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        # we need this step to fit the sklearn pipeline
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # return result as self
        return self

    def transform(self, X):
        # Check the input of function
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X should be a dataframe")

        # so that we do not over-write the original dataframe
        X = X.copy()

        # Generate the data frame to return
        if "home.dest" in X.columns.tolist():
            X = X.rename(columns={"home.dest": "homedest"})

        # return result as data frame
        return X
